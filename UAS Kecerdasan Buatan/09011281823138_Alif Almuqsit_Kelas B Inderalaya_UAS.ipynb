{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RowNumber</th>\n",
       "      <th>CustomerId</th>\n",
       "      <th>Surname</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>15634602</td>\n",
       "      <td>Hargrave</td>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>15647311</td>\n",
       "      <td>Hill</td>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>15619304</td>\n",
       "      <td>Onio</td>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>15701354</td>\n",
       "      <td>Boni</td>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>15737888</td>\n",
       "      <td>Mitchell</td>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>9996</td>\n",
       "      <td>15606229</td>\n",
       "      <td>Obijiaku</td>\n",
       "      <td>771</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>39</td>\n",
       "      <td>5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>96270.64</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>9997</td>\n",
       "      <td>15569892</td>\n",
       "      <td>Johnstone</td>\n",
       "      <td>516</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>35</td>\n",
       "      <td>10</td>\n",
       "      <td>57369.61</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101699.77</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>9998</td>\n",
       "      <td>15584532</td>\n",
       "      <td>Liu</td>\n",
       "      <td>709</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>36</td>\n",
       "      <td>7</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>42085.58</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>9999</td>\n",
       "      <td>15682355</td>\n",
       "      <td>Sabbatini</td>\n",
       "      <td>772</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Male</td>\n",
       "      <td>42</td>\n",
       "      <td>3</td>\n",
       "      <td>75075.31</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>92888.52</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>10000</td>\n",
       "      <td>15628319</td>\n",
       "      <td>Walker</td>\n",
       "      <td>792</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>28</td>\n",
       "      <td>4</td>\n",
       "      <td>130142.79</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>38190.78</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows Ã— 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      RowNumber  CustomerId    Surname  CreditScore Geography  Gender  Age  \\\n",
       "0             1    15634602   Hargrave          619    France  Female   42   \n",
       "1             2    15647311       Hill          608     Spain  Female   41   \n",
       "2             3    15619304       Onio          502    France  Female   42   \n",
       "3             4    15701354       Boni          699    France  Female   39   \n",
       "4             5    15737888   Mitchell          850     Spain  Female   43   \n",
       "...         ...         ...        ...          ...       ...     ...  ...   \n",
       "9995       9996    15606229   Obijiaku          771    France    Male   39   \n",
       "9996       9997    15569892  Johnstone          516    France    Male   35   \n",
       "9997       9998    15584532        Liu          709    France  Female   36   \n",
       "9998       9999    15682355  Sabbatini          772   Germany    Male   42   \n",
       "9999      10000    15628319     Walker          792    France  Female   28   \n",
       "\n",
       "      Tenure    Balance  NumOfProducts  HasCrCard  IsActiveMember  \\\n",
       "0          2       0.00              1          1               1   \n",
       "1          1   83807.86              1          0               1   \n",
       "2          8  159660.80              3          1               0   \n",
       "3          1       0.00              2          0               0   \n",
       "4          2  125510.82              1          1               1   \n",
       "...      ...        ...            ...        ...             ...   \n",
       "9995       5       0.00              2          1               0   \n",
       "9996      10   57369.61              1          1               1   \n",
       "9997       7       0.00              1          0               1   \n",
       "9998       3   75075.31              2          1               0   \n",
       "9999       4  130142.79              1          1               0   \n",
       "\n",
       "      EstimatedSalary  Exited  \n",
       "0           101348.88       1  \n",
       "1           112542.58       0  \n",
       "2           113931.57       1  \n",
       "3            93826.63       0  \n",
       "4            79084.10       0  \n",
       "...               ...     ...  \n",
       "9995         96270.64       0  \n",
       "9996        101699.77       0  \n",
       "9997         42085.58       1  \n",
       "9998         92888.52       1  \n",
       "9999         38190.78       0  \n",
       "\n",
       "[10000 rows x 14 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# Artificial Neural Network\n",
    "# Part 1 - Import Data and Extract input 'x' and output 'y'\n",
    "\n",
    "# Pip or Conda Install these libraries in the Terminal\n",
    "# Install Theano (U. Montreal, GPU or CPU parallel Float Point computation)\n",
    "# Install Tensorflow (Google, same as above)\n",
    "# Install Keras (Combines the above 2 libraries with a high-level API)\n",
    "\n",
    "# Numpy is a high speed Math computation library\n",
    "import numpy as np\n",
    "\n",
    "# Matplotlib is used for plotting graphs\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Pandas is a database analysis tool\n",
    "import pandas as pd\n",
    "\n",
    "# LabelEncoder is used to encode binary categorical data into numbers (male/female -> 0/1)\n",
    "# OneHotEncoder is used to encode categorical data with more than 2 possible options (France, Spain, Germany)\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "\n",
    "# Management column after converting to categorical label in dataset\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "# Split the dataset into the Training set and Test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Feature Scaling eases computation by standardizing input data\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "# Your CSV data URL link goes here\n",
    "data_url = 'https://raw.githubusercontent.com/AMoazeni/Machine-Learning-Database-Prediction/master/Data/Bank_Customer_Data.csv'\n",
    "\n",
    "# Importing the dataset\n",
    "dataset = pd.read_csv(data_url)\n",
    "\n",
    "# Display data to make sure it has been imported\n",
    "display(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X input values:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>771</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>39</td>\n",
       "      <td>5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>96270.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>516</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>35</td>\n",
       "      <td>10</td>\n",
       "      <td>57369.61</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101699.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>709</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>36</td>\n",
       "      <td>7</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>42085.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>772</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Male</td>\n",
       "      <td>42</td>\n",
       "      <td>3</td>\n",
       "      <td>75075.31</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>92888.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>792</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>28</td>\n",
       "      <td>4</td>\n",
       "      <td>130142.79</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>38190.78</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      CreditScore Geography  Gender  Age  Tenure    Balance  NumOfProducts  \\\n",
       "0             619    France  Female   42       2       0.00              1   \n",
       "1             608     Spain  Female   41       1   83807.86              1   \n",
       "2             502    France  Female   42       8  159660.80              3   \n",
       "3             699    France  Female   39       1       0.00              2   \n",
       "4             850     Spain  Female   43       2  125510.82              1   \n",
       "...           ...       ...     ...  ...     ...        ...            ...   \n",
       "9995          771    France    Male   39       5       0.00              2   \n",
       "9996          516    France    Male   35      10   57369.61              1   \n",
       "9997          709    France  Female   36       7       0.00              1   \n",
       "9998          772   Germany    Male   42       3   75075.31              2   \n",
       "9999          792    France  Female   28       4  130142.79              1   \n",
       "\n",
       "      HasCrCard  IsActiveMember  EstimatedSalary  \n",
       "0             1               1        101348.88  \n",
       "1             0               1        112542.58  \n",
       "2             1               0        113931.57  \n",
       "3             0               0         93826.63  \n",
       "4             1               1         79084.10  \n",
       "...         ...             ...              ...  \n",
       "9995          1               0         96270.64  \n",
       "9996          1               1        101699.77  \n",
       "9997          0               1         42085.58  \n",
       "9998          1               0         92888.52  \n",
       "9999          1               0         38190.78  \n",
       "\n",
       "[10000 rows x 10 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Extract input Independent Variable (Matrix of Features and Observations)\n",
    "# Row number, customer ID, and name are not useful, so they're excluded\n",
    "x = dataset.iloc[:, 3:13]\n",
    "\n",
    "print('X input values:')\n",
    "display(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y output values:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0       1\n",
       "1       0\n",
       "2       1\n",
       "3       0\n",
       "4       0\n",
       "       ..\n",
       "9995    0\n",
       "9996    0\n",
       "9997    1\n",
       "9998    1\n",
       "9999    0\n",
       "Name: Exited, Length: 10000, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Extract output Dependant Variables. The last column shows whether a customer left of stayed with the bank\n",
    "y = dataset.iloc[:, 13]\n",
    "\n",
    "print('Y output values:')\n",
    "display(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the '.values' method to convert data from Pandas Dataframes to NumPy arrays\n",
    "x = x.values\n",
    "y = y.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Artificial Neural Network\n",
    "# Part 2 - Data pre-processing\n",
    "\n",
    "# In the Bank example: Convert Female/Male into 0/1\n",
    "labelencoder_x_2 = LabelEncoder()\n",
    "x[:, 2] = labelencoder_x_2.fit_transform(x[:, 2])\n",
    "\n",
    "# In the Bank example: Convert France/Germany/Spain into categorical 0/1/2\n",
    "ct = ColumnTransformer([(\"Country\", OneHotEncoder(), [1])], remainder = 'passthrough')\n",
    "x = ct.fit_transform(x)\n",
    "\n",
    "# Remove first column to avoid Dummy Variable trap\n",
    "# Two columns of binary data is enough to describe 3 categories (France, Spain, Germany)\n",
    "x = x[:, 1:]\n",
    "\n",
    "\n",
    "# Create Training and Test sets and apply Feature Scaling (standardize)\n",
    "\n",
    "# Encode the Dependent Variable\n",
    "# In Bank example we don't need to encode Dependent variables because it's already Binary\n",
    "\n",
    "# Test_size = 0.2 means 80% of data for training, 20% test\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, random_state = 0)\n",
    "\n",
    "# Feature Scaling\n",
    "sc = StandardScaler()\n",
    "x_train = sc.fit_transform(x_train)\n",
    "x_test = sc.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.7676 - accuracy: 0.7305\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.6721 - accuracy: 0.7959\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.6700 - accuracy: 0.7961\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.7119 - accuracy: 0.7965\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.6746 - accuracy: 0.8081\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.6888 - accuracy: 0.8198\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.6912 - accuracy: 0.8229\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.6723 - accuracy: 0.8230\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.6948 - accuracy: 0.8231\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.6985 - accuracy: 0.8265\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.7019 - accuracy: 0.8201\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.7295 - accuracy: 0.8254\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.6828 - accuracy: 0.8219\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.7142 - accuracy: 0.8195\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.6903 - accuracy: 0.8231\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.6631 - accuracy: 0.8214\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.6358 - accuracy: 0.8234\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 1s 996us/step - loss: 0.7048 - accuracy: 0.82170s - loss:\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.7171 - accuracy: 0.8251\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.6823 - accuracy: 0.8248\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0xd18db125b0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Artificial Neural Network\n",
    "# Part 3 - Artificial Neural Network Architecture\n",
    "\n",
    "# Importing the Keras library\n",
    "import keras\n",
    "\n",
    "# Sequential is used to initialize NN\n",
    "from keras.models import Sequential\n",
    "\n",
    "# Dense is used to build Deep layers\n",
    "from keras.layers import Dense\n",
    "\n",
    "# Dropout  is used to prevent overfitting, by using Dropout Regularization\n",
    "from keras.layers import Dropout\n",
    "\n",
    "# Initialising the ANN Sequentially (can also initialize as Graph)\n",
    "# We use Sequential Classifier because we have successive layers\n",
    "classifier = Sequential()\n",
    "\n",
    "# Adding the input layer and the first hidden layer\n",
    "# This step initializes the Wights to small random numbers\n",
    "# 'Units' is the number of hidden layers (begin with average of Input & Output layers = 11+1/2 = 6)\n",
    "# 'Kernel_initializer': Initialize weights as small random numbers\n",
    "# 'Input_dim': number Independent Variables\n",
    "# 'Activation': Rectifier Activation Function ('relu') for Hidden Layers, Sigmoid Function for Output Layer\n",
    "classifier.add(Dense(units = 6, kernel_initializer = 'uniform', activation = 'relu', input_dim = 11))\n",
    "\n",
    "# Add Dropout Regularization to first layer to prevent overfitting\n",
    "# 'p': Fraction of Neurons to drop. Start with 0.1 (10% dropped) and increment by 0.1 until overfitting is solved, don't go over 0.5\n",
    "classifier.add(Dropout(rate = 0.1))\n",
    "\n",
    "# Add the second hidden layer\n",
    "classifier.add(Dense(units = 6, kernel_initializer = 'uniform', activation = 'relu'))\n",
    "classifier.add(Dropout(rate = 0.1))\n",
    "\n",
    "# Add the output layer\n",
    "classifier.add(Dense(units = 1, kernel_initializer = 'uniform', activation = 'sigmoid'))\n",
    "classifier.add(Dropout(rate = 0.1))\n",
    "\n",
    "# Compile the ANN\n",
    "# 'optimizer': Algorithm used to find the best Weights. 'adam' is a popular Stochastic Gradient Descent Algorithm\n",
    "# 'loss' = 'binary_crossentropy' is useful for Binary Outputs with logarithmic functions\n",
    "# 'loss' = 'categorical_crossentropy' is useful for 3+ categorical Outputs\n",
    "# 'metrics' =  Used to evaluate the ANN, requires list. We use 1 metric called 'accuracy'  \n",
    "classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "# Fitting the ANN to the Training set\n",
    "# Experiment to find best 'batch_size' and 'epochs'\n",
    "classifier.fit(x_train, y_train, batch_size = 10, epochs = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This model was trained with an accuracy of 84.05 %\n",
      "\n",
      "For a new sample input:\n",
      " [0.0, 0, 600, 1, 40, 3, 60000, 2, 1, 1, 50000] \n",
      "\n",
      "Prediction - Will this customer leave the Bank?\n",
      " Result =  [[False]] \n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAVYAAAEGCAYAAAA+Ib10AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAAiMElEQVR4nO3deZgV1Z3/8fcHRNn3RTYVDS5ojJFFMcYlLpCZJJjFCcZMMOP8NMZo9kQmi4kJvzgxmnHDDK5kUcRxT+IWIuMS1CAqCIp0RKGFyCaKgEh3f+ePqo7Xtum+3VT3rb79eT1PPV331KmqU7Z8+9xTZ1FEYGZm2elQ6gKYmZUbB1Yzs4w5sJqZZcyB1cwsYw6sZmYZ26XUBWgt/ft2jL2Gdyp1MawJXljYtdRFsCZ4i828Hdu0M9eYcGy3WL+huqi8Ty7cdl9ETNyZ+7WUdhNY9xreiSfuG17qYlgTTBhySKmLYE3weMzZ6Wus31DNE/ftUVTejoOX9d/pG7aQdhNYzSz/AqihptTF2GkOrGaWG0GwPYprCsgzB1YzyxXXWM3MMhQE1WUwzN6B1cxypQYHVjOzzARQ7cBqZpYt11jNzDIUwHa3sZqZZScINwWYmWUqoLrtx1UHVjPLj2TkVdvnwGpmOSKq2al5XHLBgdXMciN5eeXAamaWmaQfqwOrmVmmalxjNTPLjmusZmYZC0R1GawY5cBqZrnipgAzswwF4u3oWOpi7LS2X+c2s7KRDBDoUNTWGEnXSVoj6dl6jn1LUkjqX5A2VVKFpKWSJhSkj5a0KD12maRGq9QOrGaWK9XpIIHGtiLcALxnFVdJw4ETgBUFaaOAycCB6TnTJdVWna8CzgBGplujK8M6sJpZbkSI6uhQ1Nb4teIhYEM9h34JfAfeNdvLJGBWRGyLiOVABTBO0mCgZ0TMi4gAfg2c1Ni93cZqZrlSU3x3q/6S5hd8nhERMxo6QdIngFci4pk63+iHAo8VfK5M07an+3XTG+TAama5kby8KjosrYuIMcVmltQV+B5wYn2H6y3OjtMb5MBqZrlR+/KqhewDjABqa6vDgAWSxpHURIcX5B0GrErTh9WT3iC3sZpZrlSHitqaKiIWRcTAiNgrIvYiCZqHRsTfgbuAyZJ2kzSC5CXVExGxGtgk6fC0N8AXgDsbu5cDq5nlRu3Iq2K2xki6CZgH7CepUtLpO7xvxGJgNrAEuBc4OyKq08NnAdeQvND6G3BPY/d2U4CZ5UpNEW/8ixERpzRyfK86n6cB0+rJNx84qCn3dmA1s9xIJmFp+1+kHVjNLDcCsb0MhrQ6sJpZbkRQVOf/vHNgNbMcUVMGCOSWA6uZ5UbgGquZWeb88srMLEOBPNG1mVmWkuWv235YavtPYGZlpOi5VnPNgdXMciPIbuRVKTmwmlmuuMZqZpahCLnGamaWpeTllYe0mpllSB4gYGaWpeTlldtYzcwy5ZFXZmYZ8sgrM7MW0IKLCbYaB1Yzy40I2F7T9gNr238CMysbSVNAh6K2xki6TtIaSc8WpF0k6XlJCyXdLql3wbGpkiokLZU0oSB9tKRF6bHL0tVaG+TAama5Up3OF9DYVoQbgIl10h4ADoqIg4EXgKkAkkYBk4ED03OmS6rtUHsVcAbJktgj67nme7gpIIcu/vpwHv9TT3r3r2LGg0sB+M0vdueeG/vSq2+yIu8Xp65i3HGbAHhxSWcu++5wNm/qQIcOcPkfX2DXzsH2t8WV3xvKwnndkeC081bz4X9+vWTP1d4MGPI23750BX0GVhE18Mff9uOOawew96itnHNhJV261fBq5a7859l7sOXNtt8pPgtZdreKiIck7VUn7f6Cj48Bn0n3JwGzImIbsFxSBTBO0ktAz4iYByDp18BJNLIEdskCq6TvAZ8DqoEa4ExgPDAjIraUqlx5cOJnN/CJL67joq/u8a70T/6/tZx81tp3pVVXwc/P2ZNvX/Yy+xz4Fm9s6EjHTgHATZcOonf/Kq575HlqamDTa/7H25qqq8SMC4ZQsagrXbpVc8W9L7DgoR587RcrufqCISx6rDsnTl7PZ85aw68vGlzq4uZEk4a09pc0v+DzjIiY0YSb/Rtwc7o/lCTQ1qpM07an+3XTG1SSpgBJ44GPAYemVfLjgZXA14CupShTnrz/8M306FNdVN4n/7cHIw7Yyj4HvgVAz77VdEzj532z+jL5nDUAdOgAvfoVd03LxoY1nahYlPzvvHVzR1ZWdKb/4O0M22cbix7rBsBTD/XgSH+LeJeadN2rxjZgXUSMKdiKDqppxa4K+F1tUj3ZooH0BpWqjXUwyX+UbQARsY6kSj4EeFDSgwCSrpI0X9JiST9O046TdHvthSSdIOm21n+E1nf39QP40nH7cfHXh7NpYxI9K1/sjAT/ccrenH3ivsy+ciAAb76eHJ/58905+8R9+ekZe/HaWrf8lMqgYW+zz0FbeX5BV15e2pnxE94A4MMfe50BQ7aXuHT5kfQK6FjU1lySppBU7E6NiNogWQkML8g2DFiVpg+rJ71BpQqs9wPDJb0gabqkoyPiMpICHxsRx6b5vhcRY4CDgaMlHQz8GThA0oA0zxeB6+u7iaQz0sA8f+36tl1b+9iUdVw/bwnTH1hK30HbmfHjIUDSFPDsE9347hUvc/Edy/jLvb146uHuVFfButW7MmrsZq68/wUOGL2Zqy8YUuKnaJ86d63mB9e8xK9+OIQtb3bkkm8M5+OnreOKe1+gS/dqqt5u+x3is1I7QKCYrTkkTQS+C3yiTpPjXcBkSbtJGkHykuqJiFgNbJJ0eNob4AvAnY3dpySBNSLeBEaTvGlbC9ws6bR6sv6LpAXAUyRv60alf2F+A3w+7Soxnh00JEfEjNqvCQP6te32xT4DqujYMflK/9FTN7D06eQr5oDB2zl4/GZ69aumc9dg7EfeoGJRF3r2rWa3LtV86KPJ18wPf2wjyxZ1KeUjtEsddwl+cM1L/Pm2Pjx6T28AVlZ05j9O2YevTNyXuXf0YfXLu5a2kDnThKaABkm6CZgH7CepUtLpwBVAD+ABSU9L+hVARCwGZgNLgHuBsyOitjZ2FnANUAH8jUZeXEEJX16lhZ4LzJW0CJhSeDz9q/EtYGxEvCbpBqBzevh64G7gLeCWiKhqrXKXyvpXd6HfoOQx/3JPL/baL2lTHX3MJm6ZPpC3tohOuwYL53XnU2esRYLDT3iDhX/pziFHvsnTj/Rgz323lfIR2qHgGxevZOWyztw2Y8A/Unv1287r6zshBZ/76qv8/jf9SljGfMm4V8Ap9SRf20D+acC0etLnAwc15d4lCayS9gNqImJZmnQI8DKwF8lfk3VAT2Az8LqkQcBHSQIxEbFK0irg+8AJrVn21vCzs/Zk4bzuvL5hF04dPYp//ebfWTivO39b3AUpaa879+crAejRu5pPnbmWc/5pXyQY95E3OOz4pP3u9O+v4ufn7Mmvzu9Ir35VfPOSFaV8rHbnwHGbOf7k13hxSWemP5B0m7v+Z4MZOmIbHz9tHQCP3tOL+2f1LWUxc8cTXTdfd+Dy9Kt8FUkV+wzgFOAeSasj4lhJTwGLgReBR+tc43fAgIhY0nrFbh1Tr3r5PWkTP7dhh/mP+/RrHPfp196TPmjYdi6+vSLTslnxFj/RnQlDPvCe9L8Cd1w74L0nGBGiyoG1eSLiSeCIeg5dnm61+U5r4DJHAldnWzIzKzXPblUikp4kaSb4ZqnLYmbZ8UTXJRQRo0tdBjNrGQ6sZmYZ8kTXZmYtoJg+qnnnwGpmuREBVWUw0bUDq5nlipsCzMwy5DZWM7MWEA6sZmbZ8ssrM7MMRbiN1cwsY6LavQLMzLLlNlYzswx5rgAzs6xF0s7a1jmwmlmuuFeAmVmGokxeXrX9JzCzshJR3NYYSddJWiPp2YK0vpIekLQs/dmn4NhUSRWSlkqaUJA+WtKi9Nhl6WqtDXJgNbNciVBRWxFuACbWSTsPmBMRI4E56WckjQImk6wGPRGYLql2aeerSJaOGpluda/5Hg6sZpYbSW00m8AaEQ8BdReLmwTMTPdnAicVpM+KiG0RsZxkHb5xkgYDPSNiXkQE8OuCc3bIbaxmlitN6G7VX9L8gs8zImJGI+cMiojVABGxWtLANH0o8FhBvso0bXu6Xze9QQ6sZpYrTehutS4ixmR02/qieTSQ3iAHVjPLjUDUtGyvgFclDU5rq4OBNWl6JTC8IN8wYFWaPqye9Aa5jdXMciWK3JrpLmBKuj8FuLMgfbKk3SSNIHlJ9UTabLBJ0uFpb4AvFJyzQ66xmll+RHZzBUi6CTiGpC22EjgfuBCYLel0YAVwMkBELJY0G1gCVAFnR0R1eqmzSHoYdAHuSbcGObCaWb5kNKQ1Ik7ZwaHjdpB/GjCtnvT5wEFNubcDq5nlSlnPbiXpchr42xER57ZIicys3QqgpqaMAyswv4FjZmbZC6Cca6wRMbPws6RuEbG55YtkZu1ZOUwb2Gh3K0njJS0Bnks/f0DS9BYvmZm1Ty3c36o1FNOP9b+ACcB6gIh4BjiqBctkZu1WcfME5P0FV1G9AiJiZZ2Zsqp3lNfMbKfkvDZajGIC60pJRwAhaVfgXNJmATOzTAVEGfQKKKYp4EvA2SQzurwCHJJ+NjNrASpyy69Ga6wRsQ44tRXKYmZWFk0BxfQK2FvS3ZLWpssc3Clp79YonJm1Q+2kV8CNwGxgMDAEuAW4qSULZWbtVO0AgWK2HCsmsCoifhMRVen2W3L/98LM2qqsFhMspYbmCuib7j4o6TxgFklA/Szwh1Yom5m1R2XQK6Chl1dP8u6lCc4sOBbAT1qqUGbWfinntdFiNDRXwIjWLIiZWVt4MVWMokZeSToIGAV0rk2LiF+3VKHMrL3K/4upYjQaWCWdT7K8wSjgj8BHgUdI1tc2M8tWGdRYi+kV8BmSpQz+HhFfBD4A7NaipTKz9qumyC3HimkK2BoRNZKqJPUkWS7WAwTMLHtlMtF1MTXW+ZJ6A1eT9BRYADzRkoUys/ZLUdxW1LWkr0taLOlZSTdJ6iypr6QHJC1Lf/YpyD9VUoWkpZImNPcZGg2sEfHliNgYEb8CTgCmpE0CZmbZy2hIq6ShJLPxjYmIg4COwGTgPGBORIwE5qSfkTQqPX4gMBGYLqljcx6hoQEChzZ0LCIWNOeGZmataBegi6TtQFdgFTCV5IU8wExgLvBdYBIwKyK2AcslVQDjgHnNuemOXNzAsQA+0tSbldILf+vHiZ+eUupiWBPs0r+y1EWwJtBrzarcvfc6xfcK6C+pcNHTGRExo/ZDRLwi6RfACmArcH9E3C9pUESsTvOsljQwPWUo8FjB9SrTtCZraIDAsc25oJlZswVNGdK6LiLG7Ohg2nY6CRgBbARukfT5Bq5X342b1fmrmJdXZmatJ7tpA48HlkfE2ojYDtwGHAG8KmkwQPpzTZq/EhhecP4wkqaDJnNgNbNcybBXwArgcEldlSzadxzJslJ3AbXtglOAO9P9u4DJknaTNAIYSTN7QBU1pNXMrNVkNPIqIh6X9D8kXUSrgKeAGUB3YLak00mC78lp/sWSZgNL0vxnR0SzFk4tZkirSJZm2TsiLpC0B7B7RLgvq5llL8MhrRFxPnB+neRtJLXX+vJPA6bt7H2LaQqYDowHTkk/bwKu3Nkbm5nVVWwzQN6nFiymKeCwiDhU0lMAEfFaugy2mVn2ynyi61rb09EHASBpALmfAsHM2qq810aLUUxTwGXA7cBASdNIpgz8/y1aKjNrv8pgldZGa6wR8TtJT5I09go4KSKea/GSmVn70wbaT4tRTK+APYAtwN2FaRGxoiULZmbtVHsIrCQrstYuKtiZZHjYUpIZYMzMMqUyeINTTFPA+ws/p7NenbmD7GZm7V6TR15FxAJJY1uiMGZm7aIpQNI3Cj52AA4F1rZYicys/WovL6+AHgX7VSRtrre2THHMrN0r98CaDgzoHhHfbqXymFl7V86BVdIuEVHV0BItZmZZEuXfK+AJkvbUpyXdBdwCbK49GBG3tXDZzKy9aUdtrH2B9SRrXNX2Zw2S2bjNzLJV5oF1YNoj4FneCai1yuDRzSyXyiC6NBRYO5LMtJ3ZAltmZo0p96aA1RFxQauVxMwMyqLa1lBgbfuzzZpZ2xLl0SugoflY610TxsysRWU4H6uk3pL+R9Lzkp6TNF5SX0kPSFqW/uxTkH+qpApJSyVNaO4j7DCwRsSG5l7UzKy5Ml7z6lLg3ojYH/gAyfLX5wFzImIkMCf9jKRRwGSSmfsmAtPTQVJNVswKAmZmrSejGquknsBRwLUAEfF2RGwEJgEz02wzgZPS/UnArIjYFhHLgQpgXHMewYHVzPKj2KCaBNb+kuYXbGfUudreJBNGXS/pKUnXSOoGDIqI1QDpz4Fp/qHAyoLzK9O0JmvytIFmZi1FNOlr/rqIGNPA8V1IRo+eExGPS7qU9Gt/A7evq1l9FFxjNbNcybCNtRKojIjH08//QxJoX5U0GCD9uaYg//CC84cBq5rzDA6sZpYvGbWxRsTfgZWS9kuTjgOWAHcBU9K0KcCd6f5dwGRJu0kaAYwkmTOlydwUYGb5ku0AgXOA30naFXgR+CJJhXK2pNOBFcDJABGxWNJskuBbBZwdEdXNuakDq5nlR8azW0XE00B97bD19tOPiGnAtJ29rwOrmeVLmQ9pNTNrdeUwpNWB1cxypdxntzIza11NmAcgzxxYzSxfHFjNzLLTxJFXueXAama5opq2H1kdWM0sP9zGamaWPTcFmJllzYHVzCxbrrGamWXNgdXMLENlskqrA6uZ5Yb7sZqZtYRo+5HVgdXMcsU1VmtRA/pt5tvnPkLf3m9RE/DHB/bljj8cwN57buDcMx+jS+cqXl3bnQv/60i2bN0VgMmfXMSE4yqoqRHTrxvLk083a5FJa6av/fg5xh29jo0bduXLnzoMgCNPWMOpZy1n+N6b+frnxrBsSU8ABg7Zyn/f8TiVL3UFYOnCnlzx0/1LVvZc8ACBhkl6MyK6t9T124PqajHjhjFULO9Hl87bufKi37PgmcF8/cvzmDFzNIuW7M6Ejyzj5EmLmTnrg+wxbCNHH/kSZ3ztE/Tru4ULz3+AfzvnJGpqvLRZa/nTXbtz96xhfHPakn+kvVzRjZ9+4yDO+cHS9+RfXdmFc/6lWUvXl61yeHnlf3E5tmFjVyqW9wNg61udWFHZi/59tzBsyBssWjIIgAXPDOHIw1cAcMTYlfzvI3uxvaojf1/Tg1V/78F+71tfsvK3R88+2YdNr7+7vrJyeTdeealbiUrU9qimuC3PWjWwStpH0r2SnpT0sKT90/SPS3pc0lOS/iRpkKQOkl6S1Lvg/Ir02ABJt0r6a7p9qDWfoxQGDXiT943YwPPL+vPSit6MH7sSgKOOeJkB/TcD0K/fFtauf+cf8Lr13ejfd0tJymvF2X3oVi6/+Qn+87oFHHjoxlIXp/SC5OVVMVsRJHVM48rv0899JT0gaVn6s09B3qlpjFkqacLOPEZr11hnAOdExGjgW8D0NP0R4PCI+CAwC/hORNSQLEv7SQBJhwEvRcSrwKXALyNiLPBp4Jr6bibpDEnzJc3fvn1zSz5Xi+rceTs//PZcrrp+LFu27sol04/gExOXcuXPf0+Xztupqkp+jarn3DJoripbG9buxpQTP8Q5nx3H1Re9j+9cuJgu3apKXaySUxS3FemrwHMFn88D5kTESGBO+hlJo4DJwIHARGC6pI7NfYZWe3klqTtwBHCL9I8QsFv6cxhws6TBwK7A8jT9ZuCHwPUkD31zmn48MKrgOj0l9YiITYX3jIgZJMGcnt2HtskY07FjDT/89lz+/PDePPr4ngCsfKUXU39yAgBDB7/BuNGVAKxb35UB/d75A9K/32bWb+ja+oW2olRt78Cm15M/ihXP9WT1yi4M23PLP15utVsZ/UuVNAz4Z5JVV7+RJk8Cjkn3ZwJzge+m6bMiYhuwXFIFMA6Y15x7t2aNtQOwMSIOKdgOSI9dDlwREe8HzgQ6p+nzgPdJGgCcBNxWcK3xBdcZWjeolofgG1/+Cysqe3Pr3aP+kdq751YApOBzn1nIH+7fF4B584dz9JEv0WmXanYfuImhgzextKJfSUpujevZ5206dEiiyO5DtzJkjy2sruxS4lKVVu0AgSJrrP1rv5Gm2xl1LvdfwHeAwhbZQRGxGiD9OTBNHwqsLMhXmaY1S6vVWCPiDUnLJZ0cEbcoqW4eHBHPAL2AV9KsUwrOCUm3A5cAz0VE7ZuY+4GvABcBSDokXT+8rBy4/xpOOOZFXny5N1f94m4ArrvxgwwdvIlPTHwegEce34P7/vw+AF5e2ZuH/rInV196J9XVHbji6sPcI6CVfec/n+XgMRvp2Xs7v37gUX47fQSbXu/EWVNfoFeft/nRlc/w4vM9+MFZh/D+0Rv5/JeXU10tamrgip/uz5tvdCr1I5RWRFMmul4XEWPqOyDpY8CaiHhS0jFFXCvTljRFC41ykFQDrCpIugS4HbgKGAx0Iql6XyBpEvBLkuD6GDA2Io5JrzMG+CtwWkTMTNP6A1cCB5D8cXgoIr7UUHl6dh8a4z5wVnYPaC1ul2WVpS6CNcG8127l9e1r6wtQRevRe1h88KivFpX34bu/82QDgfVnwL8CVSTfgHuSfOMdCxwTEavTpse5EbGfpKkAEfGz9Pz7gB9FRLOaAlqsxhoRO6oqTawn750kL6rqu8586vw1iYh1wGd3toxmlj9ZjLyKiKnAVIC0xvqtiPi8pItIvhVfmP6sjTt3ATdKugQYAowEnmju/T3yyszyI4CWXfPqQmC2pNOBFcDJABGxWNJsYAlJLffsiKhu7k0cWM0sXzKOqxExl+TtP+l7muN2kG8aSQ+CnebAama54klYzMwy5uWvzcyy5NmtzMyylQwQaPuR1YHVzPIl5zNXFcOB1cxyxTVWM7MsuY3VzCxrTZorILccWM0sX9wUYGaWocj/sivFcGA1s3xxjdXMLGNtP646sJpZvqim7bcFOLCaWX4EHiBgZpYlER4gYGaWOQdWM7OMObCamWXIbaxmZtkrh14BXnTezHIkkqaAYrZGSBou6UFJz0laLOmraXpfSQ9IWpb+7FNwzlRJFZKWSprQ3KdwYDWz/AgyC6wkq61+MyIOAA4HzpY0CjgPmBMRI4E56WfSY5OBA4GJwHRJHZvzGA6sZpYvNUVujYiI1RGxIN3fBDwHDAUmATPTbDOBk9L9ScCsiNgWEcuBCmBccx7BgdXMckURRW1Nuqa0F/BB4HFgUESshiT4AgPTbEOBlQWnVaZpTeaXV2aWL8UHzf6S5hd8nhERM+pmktQduBX4WkS8IWlH16vvQLP6fjmwmll+REB10b0C1kXEmIYySOpEElR/FxG3pcmvShocEaslDQbWpOmVwPCC04cBq4ov/DvcFGBm+ZJdrwAB1wLPRcQlBYfuAqak+1OAOwvSJ0vaTdIIYCTwRHMewTVWM8uX7EZefQj4V2CRpKfTtP8ALgRmSzodWAGcnNw2FkuaDSwh6VFwdkRUN+fGDqxmlh8BZLTmVUQ8Qv3tpgDH7eCcacC0nb23A6uZ5UhAtP2RVw6sZpYfQVNeXuWWA6uZ5YtntzIzy5gDq5lZloqeByDXHFjNLD8CKINpAx1YzSxfXGM1M8tSk4a05pYDq5nlR0C4H6uZWcYyGnlVSg6sZpYvbmM1M8tQhHsFmJllzjVWM7MsBVHdrJn6csWB1czyI8NpA0vJgdXM8sXdrczMshNAuMZqZpah8ETXZmaZK4eXV4oy6NpQDElrgZdLXY4W0B9YV+pCWJOU6+9sz4gYsDMXkHQvyX+fYqyLiIk7c7+W0m4Ca7mSNL+xtdUtX/w7K38dSl0AM7Ny48BqZpYxB9a2b0apC2BN5t9ZmXMbq5lZxlxjNTPLmAOrmVnGHFhzTNL3JC2WtFDS05IOk/Q1SV1LXTYDSW+WugyWTx55lVOSxgMfAw6NiG2S+gO7AjcDvwW2lLJ8ZrZjrrHm12CSkSXbACJiHfAZYAjwoKQHASRdJWl+WrP9cZp2nKTbay8k6QRJt7X+I7Q/kvaRdK+kJyU9LGn/NP3jkh6X9JSkP0kaJKmDpJck9S44vyI9NkDSrZL+mm4fKtlDWdNFhLccbkB34GngBWA6cHSa/hLQvyBf3/RnR2AucDAg4HlgQHrsRuDjpX6mctuAN+tJmwOMTPcPA/6c7vfhnV44/w5cnO5fCnyxIP+fCn5nR6b7ewDPlfp5vRW/uSkgpyLiTUmjgQ8DxwI3Szqvnqz/IukMkmadwcCoiFgo6TfA5yVdD4wHvtBaZW+vJHUHjgBukVSbvFv6cxjJ73AwSZPO8jT9ZuCHwPXA5PQzwPHAqILr9JTUIyI2tehDWCYcWHMsIqpJaqFzJS0CphQelzQC+BYwNiJek3QD0Dk9fD1wN/AWcEtEVLVWuduxDsDGiDiknmOXA5dExF2SjgF+lKbPA94naQBwEvDTgmuNj4itLVheayFuY80pSftJGlmQdAjJ7FybgB5pWk9gM/C6pEHAR2szR8QqYBXwfeCGVihyuxcRbwDLJZ0MoMQH0sO9gFfS/SkF5wRwO3AJydf99emh+4Gv1OaTdEjLlt6y5BprfnUHLk9fbFQBFcAZwCnAPZJWR8Sxkp4CFgMvAo/WucbvSNpZl7ResduVrpIqCz5fApwKXCXp+0AnYBbwDEkN9RZJrwCPASMKzrsZ+CtwWkHaucCVkhaS/Dt9CPhSyzyGZc1DWsuYpCuApyLi2lKXxaw9cWAtU5KeJGkmOCHSLltm1jocWM3MMuaXV2ZmGXNgNTPLmAOrmVnGHFgNAEnV6Qxaz0q6ZWdm0JJ0g6TPpPvXSBrVQN5jJB3RjHu8lE5MU1R6nTxNmpVK0o8kfaupZbT2y4HVam2NiEMi4iDgber0mZTUsTkXjYh/b6Qf7TEkw0DNyoYDq9XnYZJhlsdIelDSjcAiSR0lXZTOtrRQ0pnwjxFGV0haIukPwMDaC0maK2lMuj9R0gJJz0iaI2kvkgD+9bS2/OEdzeokqZ+k+9PZof6bZKKZBkm6I51lanE6n0LhsYvTssxJh5PucGYqs6byyCt7F0m7kAyNvTdNGgccFBHL0+D0ekSMlbQb8Kik+4EPAvsB7wcGAUuA6+pcdwBwNXBUeq2+EbFB0q9IZon6RZrvRuCXEfGIpD2A+4ADgPOBRyLiAkn/TDIKrTH/lt6jC/BXSbemQ0a7AQsi4puSfphe+yski/x9KSKWSTqMZFaxjzTjP6O1cw6sVquLpKfT/YeBa0m+oj8REbUzMZ0IHFzbfkoy/n0kcBRwUzppzCpJf67n+ocDD9VeKyI27KAc9c7qlN7jU+m5f5D0WhHPdK6kT6b7w9OyrgdqeGcWqd8CtzUyM5VZkziwWq2tdWdlSgPM5sIk4JyIuK9Ovn8CGhtpoiLywA5mdUrLUvRolnQGqePTa22RNJd3Zv6qK2h4ZiqzJnEbqzXFfcBZkjoBSNpXUjeSCUImp22wg0nmj61rHnB0OtUhkvqm6YWzdcGOZ3V6iGSCEyR9lGTi6Ib0Al5Lg+r+JDXmWh1IVmMA+BxJE0NDM1OZNYkDqzXFNSTtpwskPQv8N8m3ntuBZcAi4Crgf+ueGBFrSdpFb5P0DO98Fb8b+GTtyyuSWZ3GpC/HlvBO74QfA0dJWkDSJLGikbLeC+ySzg71E5IZpWptBg5M51P4CHBBmn4qcHpavsXApCL+m5i9h+cKMDPLmGusZmYZc2A1M8uYA6uZWcYcWM3MMubAamaWMQdWM7OMObCamWXs/wDpUr1JtO2xOQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Artificial Neural Network\n",
    "# Part 4 - Making predictions and evaluating the model\n",
    "\n",
    "# Predicting the Test set results\n",
    "# This gives a vector of probablities of Customers leaving the bank\n",
    "# You can rank the probabilities of customers most likely to leave the bank\n",
    "y_pred = classifier.predict(x_test)\n",
    "\n",
    "\n",
    "# Choose a threshold of which customers leave or stay (use 50% as a starting threshold)\n",
    "# This line converts probabilities into True/False\n",
    "y_pred = (y_pred > 0.5)\n",
    "\n",
    "\n",
    "# Predicting a single new observation\n",
    "# Predict if the customer with the following informations will leave the bank:\n",
    "# Geography: France\n",
    "# Credit Score: 600\n",
    "# Gender: Male\n",
    "# Age: 40\n",
    "# Tenure: 3\n",
    "# Balance: 60000\n",
    "# Number of Products: 2\n",
    "# Has Credit Card: Yes\n",
    "# Is Active Member: Yes\n",
    "# Estimated Salary: 50000\n",
    "# sc.transform Feature Scales the new prediction so the model will understand it\n",
    "# Set 1 element as a float64 to set all to float64\n",
    "\n",
    "# Change this sample input to test a new prediction\n",
    "sample_input = [0.0, 0, 600, 1, 40, 3, 60000, 2, 1, 1, 50000]\n",
    "\n",
    "new_prediction = classifier.predict(sc.transform(np.array([sample_input])))\n",
    "new_prediction = (new_prediction > 0.5)\n",
    "\n",
    "# Making the Confusion Matrix\n",
    "# Tells you the number of correct vs. incorrect observations\n",
    "# In the Confusion Matrix we get [1,1] + [2,2] Correct Predictions\n",
    "# In the Confusion Matrix we get [1,2] + [2,1] Incorrect Predictions\n",
    "# Compute accuracy = correct predictions / total predictions\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "cls = ['Stay','Leave']\n",
    "cm_display = ConfusionMatrixDisplay(cm, display_labels=cls).plot()\n",
    "\n",
    "# Measure accuracy percentage of the Training Set\n",
    "accuracy = (cm[0,0] + cm[1,1])/2000*100\n",
    "\n",
    "print('This model was trained with an accuracy of', accuracy, '%\\n')\n",
    "\n",
    "print('For a new sample input:\\n', sample_input, '\\n')\n",
    "\n",
    "print('Prediction - Will this customer leave the Bank?\\n', 'Result = ', new_prediction, '\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
