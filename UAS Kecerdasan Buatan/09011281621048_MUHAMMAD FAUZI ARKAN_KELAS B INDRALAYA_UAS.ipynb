{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UTS Artificial Intelligence\n",
    "\n",
    "Artificial Neural Network (ANN) dengan Algoritma BackPropagation\n",
    "\n",
    "Nama  : Muhammad Fauzi Arkan\n",
    "NIM   : 09011281621048\n",
    "Kelas : SK5B Indralaya\n",
    "\n",
    "Pada kasus ini akan memprediksi bagaimana pengaruh dari jam istirahat dan jam belajar dari seorang siswa terhadap nilai tes/ujian nya.\n",
    "Dalam data dibawah ditunjukkan bahwa :\n",
    "1. Apabila siswa memiliki jam untuk istirahat selama 2 jam dan jam untuk belajar selama 9 jam, maka siswa tersebut akan mendapatkan nilai 92.\n",
    "2. Apabila siswa memiliki jam untuk istirahat selama 1 jam dan jam untuk belajar selama 5 jam, maka siswa tersebut akan mendapatkan nilai 86.\n",
    "3. Apabila siswa memiliki jam untuk istirahat selama 3 jam dan jam untuk belajar selama 6 jam, maka siswa tersebut akan mendapatkan nilai 89.\n",
    "\n",
    "Dengan menggunakan Artificial Neural Network (ANN) dan Algoritma BackPropagation diharapkan agar mendapatkan prediksi yang lebih tepat (meminimalkan nilai eror) dengan melakukan perubahan - perubahan pada nilai bobotnya. Karena tujuan dari ANN adalah untuk menghasilkan nilai prediksi (output) yang semirip mungkin dengan y (nilai prediksi awal). Setelah mendapatkan nilai eror, maka kita akan mulai memperbaiki nya dengan menggunakan algoritma BackPropagation.\n",
    "\n",
    "Rumus utama untuk memperbaiki suatu bobot (W) berdasarkan eror (E) adalah :\n",
    "\n",
    "W_new = W_old - Alpha (learning rate) x Turunan Parsial E / Turunan Parsial W\n",
    "\n",
    "Rumus tersebut diatas juga berlaku untuk memperbaiki nilai bias.\n",
    "\n",
    "Referensi :\n",
    "1. Neural Network using BackPropogation in Python (https://www.youtube.com/watch?v=7qYtIveJ6hU&t=14s)\n",
    "2. Machine Learning Made Easy (https://github.com/geeksnome/machine-learning-made-easy/blob/master/backpropogation.py)\n",
    "3. CONTOH PERHITUNGAN ALGORITMA BACKPROPAGATION (https://structilmy.com/2019/07/contoh-perhitungan-algoritma-backpropagation/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n"
     ]
    }
   ],
   "source": [
    "# X = (Jam Istirahat, Jam Belajar), y = Nilai tes/ujian dari siswa\n",
    "X = np.array(([2, 9], [1, 5], [3, 6]), dtype=float)\n",
    "y = np.array(([92], [86], [89]), dtype=float)\n",
    "\n",
    "# scale units\n",
    "X = X/np.amax(X, axis=0) #jumlah maksimum dari array X\n",
    "y = y/100 # nilai maksimum untuk hasil tes/ujian adalah 100\n",
    "\n",
    "print(X)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.52732813887255\n",
      "Loss: 0.00014085125889791601\n",
      "Loss: 0.00012385613490973224\n",
      "Loss: 0.00011987887141548592\n",
      "Loss: 0.0001161148381406696\n",
      "Loss: 0.0001125200335039746\n",
      "Loss: 0.00010908390970640134\n",
      "Loss: 0.00010579670385456579\n",
      "Loss: 0.00010264931454132627\n",
      "Loss: 9.963325930157956e-05\n",
      "Input: [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Loss: 9.674063425172694e-05\n",
      "\n",
      "\n",
      "Predicted Output: [[90.57110465]\n",
      " [86.88008872]\n",
      " [89.29312275]]\n"
     ]
    }
   ],
   "source": [
    "class NeuralNetwork(object):\n",
    "    def __init__(self):\n",
    "        #parameter\n",
    "        self.inputSize = 2\n",
    "        self.outputSize = 1\n",
    "        self.hiddenSize = 3\n",
    "        \n",
    "         #bobot\n",
    "        self.W1 = np.random.randn(self.inputSize, self.hiddenSize) # (3x2) bobot matrix dari input ke hidden layer\n",
    "        self.W2 = np.random.randn(self.hiddenSize, self.outputSize) # (3x1) bobot matrix dari hidden layer ke output layer\n",
    "        \n",
    "    def feedForward(self, X):\n",
    "        #forward propogation through the network\n",
    "        self.z = np.dot(X, self.W1) #dot produk dari X (input) dan set bobot pertama (3x2)\n",
    "        self.z2 = self.sigmoid(self.z) #fungsi aktivasi\n",
    "        self.z3 = np.dot(self.z2, self.W2) #dot produk dari hidden layer (z2) dan set bobot kedua (3x1)\n",
    "        output = self.sigmoid(self.z3)\n",
    "        return output\n",
    "\n",
    "    def sigmoid(self, s, deriv=False):\n",
    "        if (deriv == True):\n",
    "            return s * (1 - s)\n",
    "        return 1/(1 + np.exp(-s))\n",
    "    \n",
    "    def backward(self, X, y, output):\n",
    "        #backward propogate through the network\n",
    "        self.output_error = y - output # error in output\n",
    "        self.output_delta = self.output_error * self.sigmoid(output, deriv=True)\n",
    "        \n",
    "        self.z2_error = self.output_delta.dot(self.W2.T) #z2 error: berapa banyak bobot hidden layer yang mempengaruhi eror dari output\n",
    "        self.z2_delta = self.z2_error * self.sigmoid(self.z2, deriv=True) #aplikasi turunan dari sigmoid untuk mengatasi eror pada z2\n",
    "        \n",
    "        self.W1 += X.T.dot(self.z2_delta) # menyesuaikan bobot set pertama (input -> hidden) \n",
    "        self.W2 += self.z2.T.dot(self.output_delta) # menyesuaikan bobot set kedua (hidden -> output)\n",
    "        \n",
    "        \n",
    "    def train(self, X, y):\n",
    "        output = self.feedForward(X)\n",
    "        self.backward(X, y, output)\n",
    "        \n",
    "NN = NeuralNetwork()\n",
    "\n",
    "for i in range(1000): #melatih Neural Network (NN) sebanyak 1000 kali\n",
    "    if (i % 100 == 0):\n",
    "        print(\"Loss: \" + str(np.mean(np.square(y - NN.feedForward(X)))))\n",
    "    NN.train(X, y)\n",
    "    \n",
    "print(\"Input: \" + str(X))\n",
    "print(\"Actual Output: \" + str(y))\n",
    "print(\"Loss: \" + str(np.mean(np.square(y - NN.feedForward(X)))))\n",
    "print(\"\\n\")\n",
    "print(\"Predicted Output: \"+ str(NN.feedForward(X)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dapat dilihat pada Prediksi Output diatas menghasilkan nilai :\n",
    "1. Siswa yang memiliki waktu istirahat selama 2 jam dan waktu belajar selama 9 jam, kemungkinan mendapatkan nilai 90.57 dari prediksi awal yaitu 92.\n",
    "2. Siswa yang memiliki waktu istirahat selama 1 jam dan waktu belajar selama 5 jam, kemungkinan mendapatkan nilai 86.88 dari prediksi awal yaitu 86.\n",
    "3. Siswa yang memiliki waktu istirahat selama 3 jam dan waktu belajar selama 6 jam, kemungkinan mendapatkan nilai 89.29 dari prediksi awal yaitu 89."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
